# Copyright 2021 - 2022 IBM Corporation

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

# http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This template runs on the target cluster
#
# This template get called out from fiveg-subnet-deploy Workflow defined in
# gitops github pointed by the channel
apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: fiveg-subnet-deploy
spec:
  templates:
  - name: handlerequest
    dag:
      tasks:
      - name: create-networks
        templateRef:
          name: network-template
          template: create-network
        arguments:
          parameters:
          - name: name
            value: "{{item.name}}"
          - name: master
            value: "{{item.master}}"
          - name: range
            value: "{{item.range}}"
          - name: start
            value: "{{item.start}}"
          - name: end
            value: "{{item.end}}"
        withParam: "{{workflow.parameters.networks}}"

      - name: create-datanetwork-and-upf
        when: "{{workflow.parameters.network_name}} != \"OVERRIDE\""
        template: create-datanetwork-and-upf

      - name: create-no-datanetwork-and-upf
        when: "{{workflow.parameters.network_name}} == \"OVERRIDE\""
        template: create-no-datanetwork-and-upf

      - name: read-upf-pod
        # a pod with same name is created for Upf CR
        dependencies: [create-no-datanetwork-and-upf, create-datanetwork-and-upf]
        templateRef:
          name: nf-template
          template: read-pod
        arguments:
          parameters:
          - name: pod_name
            value: "{{workflow.parameters.fiveg_subnet_id}}"

      - name: parse-upf-sbi-up
        dependencies: [read-upf-pod]
        template: jq-script
        arguments:
          parameters:
          - name: namespace
            value: "{{workflow.namespace}}"
          - name: json_str
            value: "{{tasks.read-upf-pod.outputs.parameters.multus-ips}}"

      - name: publish-status
        dependencies: [parse-upf-sbi-up]
        template: produce
        arguments:
          parameters:
          - name: kafka_ip
            value: "{{workflow.parameters.kafka_ip}}"
          - name: kafka_port
            value: "{{workflow.parameters.kafka_port}}"

          - name: data
            value: |
              { "msg_id": "{{workflow.parameters.msg_id}}",
                "sbi-ip": "{{tasks.parse-upf-sbi-up.outputs.parameters.sbi-ip}}",
                "up-ip": "{{tasks.parse-upf-sbi-up.outputs.parameters.up-ip}}",
              }
          - name: kafka_topic
            value: "{{workflow.parameters.topic}}"


  - name: create-datanetwork-and-upf
    dag:
      tasks:
      - name: create-datanetwork
        templateRef:
          name: network-template
          template: create-network
        arguments:
          parameters:
          - name: name
            value: "{{workflow.parameters.network_name}}"
          - name: master
            value: "{{workflow.parameters.network_master}}"
          - name: range
            value: "{{workflow.parameters.network_range}}"
          - name: start
            value: "{{workflow.parameters.network_start}}"
          - name: end
            value: "{{workflow.parameters.network_end}}"

      - name: create-upf-on-datanetwork-pool
        when: "\"{{workflow.parameters.pool}}\" != \"0.0.0.0/16\""
        dependencies: [create-datanetwork]
        templateRef:
          name: nf-template
          template: create-nf
        arguments:
          parameters:
          - name: nf_apiversion
            value: "5g.ibm.com/v1alpha1"
          - name: nf_kind
            value: Upf
          - name: nf_name
            value: "{{workflow.parameters.fiveg_subnet_id}}"
          - name: success_condition
            value: "status.outputs.podname == {{workflow.parameters.fiveg_subnet_id}}"
          - name: nf_spec
            value: |
              {
                "config": {
                  "image": "{{workflow.parameters.registry}}/weit/free5gc-upf-tools:v3.0.6",
                  "image_init": "{{workflow.parameters.registry}}/weit/5ginitcontainer",
                  "upf_name": "{{workflow.parameters.fiveg_subnet_id}}",
                  "data_network_name": "{{workflow.parameters.network_name}}",
                  "dnns": [
                    {
                      "dnn_name": "internet",
                      apn_cidr: "{{workflow.parameters.pool}}"
                    }
                  ]
                }
              }

      - name: create-upf-on-datanetwork
        when: "\"{{workflow.parameters.pool}}\" == \"0.0.0.0/16\""
        dependencies: [create-datanetwork]
        templateRef:
          name: nf-template
          template: create-nf
        arguments:
          parameters:
          - name: nf_apiversion
            value: "5g.ibm.com/v1alpha1"
          - name: nf_kind
            value: Upf
          - name: nf_name
            value: "{{workflow.parameters.fiveg_subnet_id}}"
          - name: success_condition
            value: "status.outputs.podname == {{workflow.parameters.fiveg_subnet_id}}"
          - name: nf_spec
            value: |
              {
                "config": {
                  "image": "{{workflow.parameters.registry}}/weit/free5gc-upf-tools:v3.0.6",
                  "image_init": "{{workflow.parameters.registry}}/weit/5ginitcontainer",
                  "upf_name": "{{workflow.parameters.fiveg_subnet_id}}",
                  "data_network_name": "{{workflow.parameters.network_name}}"
                }
              }


  - name: create-no-datanetwork-and-upf
    dag:
      tasks:
      - name: create-upf-pool
        when: "\"{{workflow.parameters.pool}}\" != \"0.0.0.0/16\""
        templateRef:
          name: nf-template
          template: create-nf
        arguments:
          parameters:
          - name: nf_apiversion
            value: "5g.ibm.com/v1alpha1"
          - name: nf_kind
            value: Upf
          - name: nf_name
            value: "{{workflow.parameters.fiveg_subnet_id}}"
          - name: success_condition
            value: "status.outputs.podname == {{workflow.parameters.fiveg_subnet_id}}"            
          - name: nf_spec
            value: |
              {
                "config": {
                  "image": "{{workflow.parameters.registry}}/weit/free5gc-upf-tools:v3.0.6",
                  "image_init": "{{workflow.parameters.registry}}/weit/5ginitcontainer",
                  "upf_name": "{{workflow.parameters.fiveg_subnet_id}}",
                  "dnns": [
                    {
                      "dnn_name": "internet",
                      apn_cidr: "{{workflow.parameters.pool}}"
                    }
                  ]
                }
              }

      - name: create-upf
        when: "\"{{workflow.parameters.pool}}\" == \"0.0.0.0/16\""
        templateRef:
          name: nf-template
          template: create-nf
        arguments:
          parameters:
          - name: nf_apiversion
            value: "5g.ibm.com/v1alpha1"
          - name: nf_kind
            value: Upf
          - name: nf_name
            value: "{{workflow.parameters.fiveg_subnet_id}}"
          - name: success_condition
            value: "status.outputs.podname == {{workflow.parameters.fiveg_subnet_id}}"            
          - name: nf_spec
            value: |
              {
                "config": {
                  "image": "{{workflow.parameters.registry}}/weit/free5gc-upf-tools:v3.0.6",
                  "image_init": "{{workflow.parameters.registry}}/weit/5ginitcontainer",
                  "upf_name": "{{workflow.parameters.fiveg_subnet_id}}"
                }
              }

  - name: jq-script
    inputs:
      parameters:
      - name: namespace
      - name: json_str
    script:
      image: docker.pkg.github.com/5gzorro/issm/python:alpine3.6-kafka-v0.1
      imagePullPolicy: IfNotPresent
      command: [sh]
      source: |
        echo '{{inputs.parameters.json_str}}' | jq -r . | jq -r '.[] | select(.name=="{{inputs.parameters.namespace}}/up") | .ips[0]' > /tmp/up-ip.txt
        echo '{{inputs.parameters.json_str}}' | jq -r . | jq -r '.[] | select(.name=="{{inputs.parameters.namespace}}/sbi") | .ips[0]' > /tmp/sbi-ip.txt

    outputs:
      parameters:
      - name: sbi-ip
        valueFrom:
          path: /tmp/sbi-ip.txt

      - name: up-ip
        valueFrom:
          path: /tmp/up-ip.txt

  - name: produce
    # Publish a message into kafka broker
    #
    # Parameters
    # kafka_topic: the topic to publish the message on (string)
    # kafka_ip: ipaddress of the kafka broker (string)
    # kafka_port: kafka broker port (number)
    # data: the payload to publish (json)
    inputs:
      parameters:
      - name: kafka_topic
      - name: kafka_ip
      - name: kafka_port
      - name: data
    script:
      image: docker.pkg.github.com/5gzorro/issm/python:alpine3.6-kafka-v0.1
      imagePullPolicy: IfNotPresent
      command: [python]
      source: |
        import json
        import os

        from kafka import KafkaProducer
        from kafka.errors import KafkaError

        KAFKA_TOPIC = '{{inputs.parameters.kafka_topic}}'
        KAFKA_TIMEOUT = 10
        KAFKA_API_VERSION = (1, 1, 0)

        KAFKA_SERVER = "{}:{}".format("{{inputs.parameters.kafka_ip}}", "{{inputs.parameters.kafka_port}}")
        producer = KafkaProducer(bootstrap_servers=KAFKA_SERVER,
                                 api_version=KAFKA_API_VERSION,
                                 value_serializer=lambda v: json.dumps(v).encode('utf-8'))

        t = producer.send(KAFKA_TOPIC, {{inputs.parameters.data}})
        # Block for 'synchronous' send; set timeout on X seconds
        try:
            t.get(timeout=KAFKA_TIMEOUT)
        except KafkaError as ke:
            print("1")
        print ("0")
